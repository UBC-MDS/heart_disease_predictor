{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4da52cc7-d6ad-4b36-915d-10f2c4516f32",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Output, Results and Discussions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd68811-23a2-48c6-9654-9b644650ae6b",
   "metadata": {},
   "source": [
    "### Model Selection\n",
    "\n",
    "In order to predict heart disease in patients based on the different health indicators provided in the dataset, we decided to try two different models, `LogisticRegression` and `SVC` (support vector classifier), with default parameters as well as the `DummyClassifier` as a base model for comparison. We conducted 5-fold cross validation on the train set and extracted the mean fit time, score time, test score and train score for each model as well as the standard deviations to compare the models and select one for hyperparameter optimization. We used the f1 score as opposed to accuracy as our scoring metric due to the class imbalance we observed during our EDA. The results are listed in the table below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "719a66aa-2acd-4311-b0f0-40c79d804bf7",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4cc77c70",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dummy: Mean</th>\n",
       "      <th>Dummy: Std</th>\n",
       "      <th>SVC: Mean</th>\n",
       "      <th>SVC: Std</th>\n",
       "      <th>LogisticRegression: Mean</th>\n",
       "      <th>LogisticRegression: Std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fit_time</th>\n",
       "      <td>0.002</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score_time</th>\n",
       "      <td>0.002</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_score</th>\n",
       "      <td>0.726</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.870</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.836</td>\n",
       "      <td>0.012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_score</th>\n",
       "      <td>0.726</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.908</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.885</td>\n",
       "      <td>0.008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Dummy: Mean  Dummy: Std  SVC: Mean  SVC: Std  \\\n",
       "fit_time           0.002       0.001      0.009     0.001   \n",
       "score_time         0.002       0.001      0.006     0.001   \n",
       "test_score         0.726       0.007      0.870     0.038   \n",
       "train_score        0.726       0.002      0.908     0.003   \n",
       "\n",
       "             LogisticRegression: Mean  LogisticRegression: Std  \n",
       "fit_time                        0.012                    0.001  \n",
       "score_time                      0.005                    0.000  \n",
       "test_score                      0.836                    0.012  \n",
       "train_score                     0.885                    0.008  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"../../results/model_selection_results.csv\", index_col=0, header = 0, names=[\"Dummy: Mean\", \"Dummy: Std\", \"SVC: Mean\", \"SVC: Std\", \"LogisticRegression: Mean\", \"LogisticRegression: Std\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb539645",
   "metadata": {},
   "source": [
    "Table 1: Cross validation and Train mean f1 scores and standard deviation by model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02912624",
   "metadata": {},
   "source": [
    "Based on these results, we could see that the `DummyClassifier` model already performs quite well at predicting the presence of disease. However, both `SVC` and `LogisticRegession` had higher mean cross validation f1 scores and were already performing better than the `DummyClassifier` with default values. `SVC` has the higher mean cross validation f1 score compared to `LogisticRegression` so we decided to continue with this model for downstream hyperparameter tuning. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7783d7c",
   "metadata": {},
   "source": [
    "### Hyperparameter Optimization\n",
    "\n",
    "To conduct hyperparameter optimization, we decided to use `RandomizedSearchCV` with 50 iterations to search through optimal values for `C` and `gamma` for the `SVC` model. We used the loguniform distribtuion from $10^{-3}$ to $10^3$ for both hyperparameters. We also looked at f1, recall, and precision scores to compare the models. The mean cross validation f1 scores from the top 5 results of this search are listed below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9fb31a34",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>param_svc__C</th>\n",
       "      <th>param_svc__gamma</th>\n",
       "      <th>mean_test_f1</th>\n",
       "      <th>std_test_f1</th>\n",
       "      <th>mean_train_f1</th>\n",
       "      <th>std_train_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.021412</td>\n",
       "      <td>0.023231</td>\n",
       "      <td>5.542653</td>\n",
       "      <td>0.004940</td>\n",
       "      <td>0.870002</td>\n",
       "      <td>0.036278</td>\n",
       "      <td>0.885719</td>\n",
       "      <td>0.008873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.020799</td>\n",
       "      <td>0.021039</td>\n",
       "      <td>2.191347</td>\n",
       "      <td>0.008990</td>\n",
       "      <td>0.864217</td>\n",
       "      <td>0.036591</td>\n",
       "      <td>0.879164</td>\n",
       "      <td>0.005463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.029400</td>\n",
       "      <td>0.020799</td>\n",
       "      <td>0.358907</td>\n",
       "      <td>0.074742</td>\n",
       "      <td>0.857567</td>\n",
       "      <td>0.037695</td>\n",
       "      <td>0.894765</td>\n",
       "      <td>0.004161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.029684</td>\n",
       "      <td>0.022001</td>\n",
       "      <td>0.768407</td>\n",
       "      <td>0.225271</td>\n",
       "      <td>0.857033</td>\n",
       "      <td>0.033634</td>\n",
       "      <td>0.951647</td>\n",
       "      <td>0.006082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.023398</td>\n",
       "      <td>0.019897</td>\n",
       "      <td>113.254281</td>\n",
       "      <td>0.003156</td>\n",
       "      <td>0.854928</td>\n",
       "      <td>0.025702</td>\n",
       "      <td>0.898059</td>\n",
       "      <td>0.006965</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  param_svc__C  param_svc__gamma  \\\n",
       "1       0.021412         0.023231      5.542653          0.004940   \n",
       "2       0.020799         0.021039      2.191347          0.008990   \n",
       "3       0.029400         0.020799      0.358907          0.074742   \n",
       "4       0.029684         0.022001      0.768407          0.225271   \n",
       "5       0.023398         0.019897    113.254281          0.003156   \n",
       "\n",
       "   mean_test_f1  std_test_f1  mean_train_f1  std_train_f1  \n",
       "1      0.870002     0.036278       0.885719      0.008873  \n",
       "2      0.864217     0.036591       0.879164      0.005463  \n",
       "3      0.857567     0.037695       0.894765      0.004161  \n",
       "4      0.857033     0.033634       0.951647      0.006082  \n",
       "5      0.854928     0.025702       0.898059      0.006965  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optim_df = pd.read_csv(\"../../results/optimization_results.csv\", index_col=0)\n",
    "optim_df = optim_df.iloc[:,0:5].T\n",
    "optim_df.iloc[:,0:8]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07036785",
   "metadata": {},
   "source": [
    "Table 2: Cross validation and Train mean f1 scores and standard deviation of top 5 models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8406f5e8",
   "metadata": {},
   "source": [
    "After hyperparameter optimization, we did not get an f1 score higher than the default `SVC` model, but we can see that there is a range in the difference between the validation scores and train scores even when just looking at the top 5 models. This data can help us ensure our model is neither underfit nor overfit and performs as well as possible without being overly complex. The recall and precision scores of the top 5 models are listed below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8ceb798c",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_test_recall</th>\n",
       "      <th>std_test_recall</th>\n",
       "      <th>mean_train_recall</th>\n",
       "      <th>std_train_recall</th>\n",
       "      <th>mean_test_precision</th>\n",
       "      <th>std_test_precision</th>\n",
       "      <th>mean_train_precision</th>\n",
       "      <th>std_train_precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.941799</td>\n",
       "      <td>0.043671</td>\n",
       "      <td>0.954709</td>\n",
       "      <td>0.011475</td>\n",
       "      <td>0.809546</td>\n",
       "      <td>0.043052</td>\n",
       "      <td>0.826077</td>\n",
       "      <td>0.009085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.941799</td>\n",
       "      <td>0.043671</td>\n",
       "      <td>0.949271</td>\n",
       "      <td>0.012293</td>\n",
       "      <td>0.799584</td>\n",
       "      <td>0.043485</td>\n",
       "      <td>0.818798</td>\n",
       "      <td>0.005595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.927513</td>\n",
       "      <td>0.022625</td>\n",
       "      <td>0.954709</td>\n",
       "      <td>0.008097</td>\n",
       "      <td>0.799002</td>\n",
       "      <td>0.057458</td>\n",
       "      <td>0.842102</td>\n",
       "      <td>0.012343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.905820</td>\n",
       "      <td>0.017576</td>\n",
       "      <td>0.980066</td>\n",
       "      <td>0.006777</td>\n",
       "      <td>0.813958</td>\n",
       "      <td>0.048279</td>\n",
       "      <td>0.924971</td>\n",
       "      <td>0.012734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.898148</td>\n",
       "      <td>0.043807</td>\n",
       "      <td>0.942031</td>\n",
       "      <td>0.015798</td>\n",
       "      <td>0.817520</td>\n",
       "      <td>0.032966</td>\n",
       "      <td>0.858261</td>\n",
       "      <td>0.010438</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_test_recall  std_test_recall  mean_train_recall  std_train_recall  \\\n",
       "1          0.941799         0.043671           0.954709          0.011475   \n",
       "2          0.941799         0.043671           0.949271          0.012293   \n",
       "3          0.927513         0.022625           0.954709          0.008097   \n",
       "4          0.905820         0.017576           0.980066          0.006777   \n",
       "5          0.898148         0.043807           0.942031          0.015798   \n",
       "\n",
       "   mean_test_precision  std_test_precision  mean_train_precision  \\\n",
       "1             0.809546            0.043052              0.826077   \n",
       "2             0.799584            0.043485              0.818798   \n",
       "3             0.799002            0.057458              0.842102   \n",
       "4             0.813958            0.048279              0.924971   \n",
       "5             0.817520            0.032966              0.858261   \n",
       "\n",
       "   std_train_precision  \n",
       "1             0.009085  \n",
       "2             0.005595  \n",
       "3             0.012343  \n",
       "4             0.012734  \n",
       "5             0.010438  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optim_df = optim_df.drop([\"rank_test_recall\",'rank_test_precision'], axis = 1)\n",
    "optim_df.iloc[:,8:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef4eda48",
   "metadata": {},
   "source": [
    "Table 3: Cross validation and Train mean recall and precision scores and standard deviation of top 5 models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdeddf57",
   "metadata": {},
   "source": [
    "We can see that our recall scores are higher than our precision scores with this model. Since our problem is related to disease detection, we are more concerned with keeping recall high as we are care most about reducing false negatives. A false negative in this case will involve predicting no heart disease when heart disease is indeed present which is quite dangerous. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba2918c",
   "metadata": {},
   "source": [
    "### Test Results\n",
    "\n",
    "After we had a model we were reasonably confident in, we assessed it using our test data. We achieved a f1 score of about 0.81 which is consistent with our cross-validation results and means we can be relatively confident in our model's performance to predict heart disease on deployment data. Below we have included the confusion matrix based on our test data to help visualize its performance:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58e6364",
   "metadata": {},
   "source": [
    "![ConfusionMatrix](../../results/confusion_matrix.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2642eae9-7929-45bc-bcd2-ce4b90d6a215",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "In conclusion, the `SVC` model seems to be a good candidate for this heart disease prediction task. The gap between cross-validation scores and test scores was only about 6% so we are hopeful this model will be effective on deployment data as well. However, as our dataset was relatively small, it would be interesting to see how this model would scale up and whether the limited data used in both training and testing would impact the results.\n",
    "\n",
    "## Limitations & Future Work\n",
    "In future, it would be good to try out a wider variety of models such as `RandomForestClassifier` or `linearSVC` and conduct hyperparameter optimization on multiple models before making a decision on which model to select. It would also be interesting to use `LogisticRegression` to look at feature importances and see if we can simplify our model by removing features with less relevance while still achieving similar results. Having a larger dataset to work with during training may also improve our model and improve its performance in deployment.\n",
    " \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
