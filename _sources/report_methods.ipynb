{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da3b6806-aae0-49ff-bc6f-a0da044fa942",
   "metadata": {},
   "source": [
    "# Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7be599-20fd-4d26-93c4-887edd97921e",
   "metadata": {},
   "source": [
    "## Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2f5d2e-1fa6-4d19-bfd6-4bf4f9c8ab21",
   "metadata": {},
   "source": [
    "\n",
    "The heart disease data set {cite}`misc_heart_disease_45`used in this project is obtained from the [UC Irvine machine learning repository](https://archive-beta.ics.uci.edu/dataset/45/heart+disease) {cite}`Dua:2019`. The creators Andras et al. originally donated the dataset in 1988 with 76 features. Nevertheless, the dataset we use contains 13 features with a binary target variable of 0 and 1, where 0 indicates no presence of heart and 1 indicates presence. Out of the 13 features, there are 8 categorical features and 5 numeric features. These features includes various physiological parameters like resting blood pressure and serum cholestoral levels, as well as potential signs of heart disease like chest pain. The original paper utilized Bayesian model to estimate the probability of having heart disease presence {cite}`detrano1989international`. \n",
    "\n",
    "\n",
    "There are 303 observations in the heart disease dataset with no missing values. We have a slightly imbalance dataset: there are 165 positive cases (i.e. presence of heart disease) and 138 negative cases. We split the dataset into training and test data in a stratified fashion. The number of cases in the two splits is shown in the table below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "308ad6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1520d28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Presence of HD:</th>\n",
       "      <th>No presence of HD:</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Training</th>\n",
       "      <td>138</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test</th>\n",
       "      <td>27</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Presence of HD:  No presence of HD:\n",
       "Training              138                 104\n",
       "Test                   27                  34"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"../../results/class_count.csv\", index_col = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18cf37d1-c0df-48cf-ad1d-ba13dbcff934",
   "metadata": {},
   "source": [
    "## EDA and Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8932617",
   "metadata": {},
   "source": [
    "During the EDA stage, we first created histograms for the numeric features and bar plots for the categorical features, all of them were colored by the target.\n",
    "```{figure} ../../results/numeric_distributions.png\n",
    "```\n",
    "```{figure} ../../results/categorical_distributions.png\n",
    "```\n",
    "The two plots above demonstrated the varying ranges of the feautres and it helps to highlight what sort of preprocessing will be needed in order to incorporate the features into our predictive model. \n",
    "\n",
    "Next, we created a pairwise correlation matrix for all the features and also the target to see if any particular feature might be more useful when predicting the target class.\n",
    "```{figure} ../../results/correlation_matrix.png\n",
    "```\n",
    "It seems that there are some moderate correlations between some pairs of features. Also, `max_hr_achieved` has the highest correlation with target ($\\rho = 0.44$) while `max_hr_achieved` have a moderate negative correlation with `age` ($\\rho = -0.41$). We plot `max_hr_achieved` against `age` and colored the plot by age; in addition, we fit two simple linear regression line to see if the distinction of target class is large enough just by using these two features.\n",
    "```{figure} ../../results/thalach_vs_age.png\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfbf1f9e-f930-4854-a954-acd8c2fb78dc",
   "metadata": {},
   "source": [
    "For our project, we used Python as the language of our analysis pipeline {cite}`perez2011python`. In the EDA stage, the plots and tables are created using Altair {cite}`VanderPlas2018` and Pandas {cite}`mckinney-proc-scipy-2010`. Machine learning models were built using the scikit-learn library {cite}`scikit-learn` and Scipy is also used to generate hyperparameter distributions {cite}`2020SciPy-NMeth`. Other python libraries used for our project also include docopt {cite}`docopt`, Vega-Lite {cite}`Satyanarayan2017` and Numpy {cite}`harris2020array`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
